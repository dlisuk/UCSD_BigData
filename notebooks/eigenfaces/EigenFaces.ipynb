{
 "metadata": {
  "name": "EigenFaces"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### Eigenfaces ###\nThis notebook presents the idea of eigen-faces. The data was taken from here: http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html\n\nWhen publishing work based on this data please reference the paper:\n\n**Athinodoros Georghiades, Peter Belhumeur, and David Kriegman /  \n\"From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose\", PAMI, 2001**"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "!pwd \nData_Dir='/home/ubuntu/UCSD_BigData/data/CroppedYale'\n!ls $Data_Dir\n!ls yaleB01/",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "/home/ubuntu/UCSD_BigData/data/CroppedYale\r\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "yaleB01  yaleB06  yaleB11  yaleB17  yaleB22  yaleB27  yaleB32  yaleB37\r\nyaleB02  yaleB07  yaleB12  yaleB18  yaleB23  yaleB28  yaleB33  yaleB38\r\nyaleB03  yaleB08  yaleB13  yaleB19  yaleB24  yaleB29  yaleB34  yaleB39\r\nyaleB04  yaleB09  yaleB15  yaleB20  yaleB25  yaleB30  yaleB35\r\nyaleB05  yaleB10  yaleB16  yaleB21  yaleB26  yaleB31  yaleB36\r\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "ls: cannot access yaleB01/: No such file or directory\r\n"
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### Converting from svg to png ###\nThis is already done, you can skip the following cell. Executing it requires that ImageMagik be installed."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from glob import glob\n\n%cd $Data_Dir\nfiles=glob('yaleB/*.pgm')\nprint 'number of files is',len(files)\ncount=0\nfor f in files:\n    new_f=f[:-3]+'png'\n    !convert $f $new_f\n    count += 1\n    if count % 100==0:\n        print count,f,new_f\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "/home/ubuntu/UCSD_BigData/data/CroppedYale\nnumber of files is 0\n"
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### Collect and display all images from a single person ###"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def image_grid(D,H,W,cols=10,scale=1):\n    \"\"\" display a grid of images\n        H,W: Height and width of the images\n        cols: number of columns = number of images in each row\n        scale: 1 to fill screen\n    \"\"\"\n    n=shape(D)[0]\n    rows = int(ceil((n+0.0)/cols))\n    fig=plt.figure(1,figsize=[scale*20.0/H*W,scale*20.0/cols*rows],dpi=300)\n    for i in range(n):\n        subplot(rows,cols,i+1)\n        fig=plt.imshow(reshape(D[i,:],[H,W]), cmap = cm.Greys_r)\n        plt.axis('off')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "(192*168)**2",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": "1040449536"
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import Image\nimport scipy.misc\n\nSetNo='20'   # can be any number from 01 to 39\n\n#read in files\nfiles=glob('yaleB'+SetNo+'/*.png')\nfiles=[name for name in files if name.find('Ambient')==-1]\n\nim_number=len(files)\n\nprint 'number of files:',im_number\n\n#read one file to find out the image size\nim = Image.open(files[0]).convert(\"L\")\n(H,W)=shape(im)\nprint 'shape=',(H,W)\narr=np.zeros([im_number,H*W])\n\nfor i in range(im_number):\n    im = Image.open(files[i]).convert(\"L\")\n    arr[i,:] = np.reshape(np.asarray(im),[1,H*W])\n\nimage_grid(arr,H,W)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "shape(im)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "image_i=10\nfig=plt.figure(1,figsize=[10,5],dpi=300)\nsubplot(1,2,1)\nplt.imshow(np.reshape(arr[image_i,:],[H,W]), cmap = cm.Greys_r)\n# Testing flattening and deflattenning\nflat=np.reshape(arr[image_i,:],[H*W])\nflat=(flat-mean(flat))/std(flat)\nrecon=np.reshape(flat,[H,W])\n# Shifting and scaling the image does not change how it is displayed\nsubplot(1,2,2)\nplt.imshow(recon, cmap = cm.Greys_r)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Normalize all of the images to have mean zero and std 1\nmeans=np.zeros(im_number)\nstds=np.zeros(im_number)\nmeans2=np.zeros(im_number)\nstds2=np.zeros(im_number)\n\nD0=np.zeros([im_number,H*W])  #the normalized data\n\nfor i in range(im_number):\n    flat=arr[i,:]\n    means[i]=mean(flat)\n    stds[i]=std(flat)\n    D0[i,:]=(flat-means[i])/stds[i]\n    means2[i]=mean(D0[i,:])\n    stds2[i]=std(D0[i,:])\nprint 'means=',means, \nprint 'means2=',means2 \nprint 'stds=',stds\nprint 'stds2=',stds2",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### Finding the mean image ###"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "mean_image=zeros(H*W)\nfor i in range(im_number):\n    mean_image=mean_image+D0[i,:]\nmean_image=mean_image/im_number\nplt.imshow(np.reshape(mean_image,[H,W]), cmap = cm.Greys_r)\nfigure()\nhist(mean_image,bins=100);",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Note how flat the illumination seems to be on this one!"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### Subtracting out the mean image ###"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "D1=0*D0\nfor i in range(im_number):\n    D1[i,:]=D0[i,:] - mean_image\nimage_grid(D0[:10,:],H,W)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "image_grid(D1[:10,:],H,W)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### Compute the average lengths of vectors ###"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def err(V):\n    \"\"\" err = the average of the square values \"\"\"\n    return np.dot(V,V)/len(V)\n\ndef meanErr(D):\n    \"\"\" meanErr = the average err over all rows of D \"\"\"\n    total_err=0\n    n=shape(D)[0]\n    for i in range(n):\n        total_err += err(D[i,:])\n    return total_err/n\nprint 'before subtracting mean mean err=',meanErr(D0)\nprint 'after subtracting mean mean err=',meanErr(D1)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### Using iterative PCA to find the largest eigen-vector ###"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from numpy.linalg import norm\n\nk=20; L=10\n\nR=copy(D1)   #R is a matrix in which each row is the residual vector after the current eigenvectors have been projected out.\neigvecs=np.zeros([k,H*W])\nCoeffs=np.zeros([im_number,k])  # Coeffs holds the coefficients of the eigenvectors that approximate each image\nvar_remaining=np.zeros(k)\n\nfactor=im_number*H*W\n\nfor e in range(k):\n    print 'starting on eigenvec',e\n    V=np.random.normal(size=H*W)  # V is the \"current vector\" in the eigenvector finding algorithm.\n    V=V/norm(V)\n\n    # Iterate L times through the data to find the next eigenvector.\n    for j in range(L):\n        acc_length=0; acc_explained=0\n        Vprev=V/norm(V)\n        for i in range(im_number):\n            X=R[i,:]\n            d=np.dot(V,X)/norm(V)\n            V=V+d*X\n            #print acc_length,acc_explained\n            acc_length += np.dot(X,X)\n            acc_explained += d*d\n        NV=V/norm(V) # normalized version of updated vector\n        print '%4d: change=%5.4f, total variance=%5.4f, captured variance=%5.4f' % (j,norm(NV-Vprev),acc_length/factor,acc_explained/factor)\n    var_remaining[e]=acc_length/factor\n    eigvecs[e,:]=NV\n    # subtract projection on V from each data vector\n    for i in range(im_number):\n        X=R[i,:]\n        d=np.dot(X,NV)\n        Coeffs[i,e]=d\n        X=X-NV*d\n        R[i,:]=X",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print var_remaining/var_remaining[0]\nplot(var_remaining/var_remaining[0]);\ngrid()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "tmp=np.zeros([k+1,H*W])\ntmp[0,:]=mean_image\ntmp[1:,:]=eigvecs\nimage_grid(tmp,H,W,cols=5)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### Reconstruction of specific images ###\nFrom the analysis above it is clear that the top k eigenvectors explain most of the variance"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "im=21\nApprox=np.zeros([k+2,H*W])\nApprox[0,:]=mean_image\nfor i in range(1,k+1):\n    Approx[i,:]=Approx[i-1,:]+Coeffs[im,i-1]*eigvecs[i-1,:]\nApprox[k+1,:]=D0[im,:]\nimage_grid(Approx,H,W,cols=5)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "## Excercises ##\nSee answers in below sections\n\n1. Alter the cell \"Reconstruction of specific images\" so that under each of the reconstruction you'll have the average per-pixel squared error. Take a square root on the outside to make the be a Root-Mean-Square quantity.\n\n2. There seems to be a bug in the reconstruction code above, the findal reconstruction is quite different from the image to be reconstructed. Can you find the bug?\n\n3. Use the eigenvectors to model the difference between faces (keeping the illumination fixed). How many eigenvectors do you need in order to have a good reconstruction?"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### (1) Reconstruction of specific images ###\nFor excercise 1 I duplicate the image_grid function and reconstruction plotting cells.\nI modify image grid function to take an addition parameter _labels_ which which contains a list of labels you wish to be put below each image.\nI then calculate mean squared error and root mean square error"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def image_grid_2(D,H,W,cols=10,scale=1,labels=None):\n    \"\"\" display a grid of images\n        H,W: Height and width of the images\n        cols: number of columns = number of images in each row\n        scale: 1 to fill screen\n    \"\"\"\n    n=shape(D)[0]\n    rows = int(ceil((n+0.0)/cols))\n    fig=plt.figure(1,figsize=[scale*20.0/H*W,scale*20.0/cols*rows],dpi=300)\n    for i in range(n):\n        subplot(rows,cols,i+1)\n        fig=plt.imshow(reshape(D[i,:],[H,W]), cmap = cm.Greys_r)\n        #Put the relevant label as the xlabel for the current plot\n        if labels != None:\n            plt.xlabel(labels[i])            \n        #Setting axis to be off disables printing of the xlabel, instead we turn off the unwanted elements\n        plt.axis(frameon = 0)\n        plt.gca().set_xticks([])\n        plt.gca().set_yticks([])",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "im=21\nApprox=np.zeros([k+2,H*W])\nApprox[0,:]=mean_image\nerror = [0]*(k+2)\nfor i in range(1,k+1):\n    Approx[i,:]=Approx[i-1,:]+Coeffs[im,i-1]*eigvecs[i-1,:]\nfor i in range(0,k+1):\n    error[i] = np.square(Approx[i,:] - D0[im,:]).sum()/(H*W)\nlabels = [\"MSE = %0.2f RMSE = %0.2f\" % (x,np.sqrt(x)) for x in error]\nApprox[k+1,:]=D0[im,:]\nimage_grid_2(Approx,H,W,cols=5, labels=labels)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### (2) Error in reconstruction ###\n\nThere seems to be a bug in the reconstruction code above, the findal reconstruction is quite different from the image to be reconstructed. Can you find the bug?\n\nAs an investigation we first try using more eigenvectors in the reconstruction"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from numpy.linalg import norm\n\nk=50; L=10\n\nR=copy(D1)   #R is a matrix in which each row is the residual vector after the current eigenvectors have been projected out.\neigvecs=np.zeros([k,H*W])\nCoeffs=np.zeros([im_number,k])  # Coeffs holds the coefficients of the eigenvectors that approximate each image\nvar_remaining=np.zeros(k)\n\nfactor=im_number*H*W\n\nfor e in range(k):\n    print 'starting on eigenvec',e\n    V=np.random.normal(size=H*W)  # V is the \"current vector\" in the eigenvector finding algorithm.\n    V=V/norm(V)\n\n    # Iterate L times through the data to find the next eigenvector.\n    for j in range(L):\n        acc_length=0; acc_explained=0\n        Vprev=V/norm(V)\n        for i in range(im_number):\n            X=R[i,:]\n            d=np.dot(V,X)/norm(V)\n            V=V+d*X\n            #print acc_length,acc_explained\n            acc_length += np.dot(X,X)\n            acc_explained += d*d\n        NV=V/norm(V) # normalized version of updated vector\n        print '%4d: change=%5.4f, total variance=%5.4f, captured variance=%5.4f' % (j,norm(NV-Vprev),acc_length/factor,acc_explained/factor)\n    var_remaining[e]=acc_length/factor\n    eigvecs[e,:]=NV\n    # subtract projection on V from each data vector\n    for i in range(im_number):\n        X=R[i,:]\n        d=np.dot(X,NV)\n        Coeffs[i,e]=d\n        X=X-NV*d\n        R[i,:]=X",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Now we investigate the top coefficients for image 21\nim=21\nplot(Coeffs[im,1:])",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "We cna see that after eigenvector 20 there are still several eigen vectors with large coefficients.  These are probably the cause of the bad reconstruction.\n\nFrom here we now see that the error (per pixel root mean squred error) continues to impprove significantly after 20 components.  There are even  several eigenvectors which cause a drop of several percentage points singlehandedly."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "im=21\nApprox=np.zeros([k+2,H*W])\nApprox[0,:]=mean_image\nerror = []\nfor i in range(1,k+1):\n    Approx[i,:]=Approx[i-1,:]+Coeffs[im,i-1]*eigvecs[i-1,:]\nfor i in range(0,k+1):\n    error.append(np.sqrt(np.square(Approx[i,:] - D0[im,:]).sum()/(H*W)))\n    \nApprox[k+1,:]=D0[im,:]\n\n\nplot(error[:])\nplt.title(\"RMS Error of reconstruction\")\n\nplt.figure()\nplot(error[20:])\nplt.title(\"RMS Error of reconstruction after 20 eigen vectors\")",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "We now compare the approximation after 50 eigenvectors and see that the reconstruction is now much closer.  THere is still ~1-2% rms error, which is still visible, however, it can be assumed our improvements will continue with more eigen vectors.  An interesting exercise would be to build a reconstruction with the 10-20 eigen vectores with the highest magnitude of coefficient (even if they aren't the ones of highest varience from pca)."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "image_grid_2(Approx[-2:],H,W,cols=5)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**Mofei** What's your conclusion? Is there is bug? Do you think the reconstruction is bad or it's just the way it behaves?"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "### (3) Between Face Differences ###\nHere we now model distinct faces to allow user identification"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "First I look at all images for individual 20 but put the name of the image under the image using image_grid_2.  From this it is easy to find a pose/lighting pattern that will work well for user identification."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import re\n#read in files\nfiles=glob('yaleB20/*.png')\nfiles=[name for name in files if name.find('Ambient')==-1]\n\nim_number=len(files)\n\n\n#read one file to find out the image size\nim = Image.open(files[0]).convert(\"L\")\n(H,W)=shape(im)\narr=np.zeros([im_number,H*W])\n\nfor i in range(im_number):\n    im = Image.open(files[i]).convert(\"L\")\n    arr[i,:] = np.reshape(np.asarray(im),[1,H*W])\nfilenames = [re.sub(\"^.*/\",\"\",x) for x in files]\nimage_grid_2(arr,H,W,labels=filenames, cols = 5)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "From this it lookes like P00A-025E+00 is a good pose/lighting condition for our purposes.\n\nNow we load this pose for all 38 distinct people and display a grid of users."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import Image\nimport scipy.misc\n\n\n#read in files\nfiles=glob('yaleB*/*P00A-025E+00.png')\nfiles=[name for name in files if name.find('Ambient')==-1]\n\nim_number=len(files)\n\nprint 'number of files:',im_number\n\n#read one file to find out the image size\nim = Image.open(files[0]).convert(\"L\")\n(H,W)=shape(im)\nprint 'shape=',(H,W)\narr=np.zeros([im_number,H*W])\n\nfor i in range(im_number):\n    im = Image.open(files[i]).convert(\"L\")\n    arr[i,:] = np.reshape(np.asarray(im),[1,H*W])\n\nimage_grid(arr,H,W)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Normalize all of the images to have mean zero and std 1\nmeans=np.zeros(im_number)\nstds=np.zeros(im_number)\nmeans2=np.zeros(im_number)\nstds2=np.zeros(im_number)\n\nmu  = np.repeat(np.matrix(arr.mean(1)).transpose(),arr.shape[1],1)\nsig = np.repeat(np.matrix(arr.std(1)).transpose(),arr.shape[1],1)\narr_std = np.divide(arr - mu,sig)\n(arr_std.mean(1).max(), arr_std.mean(1).min(),arr_std.std(1).max(),arr_std.std(1).min())",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "image_grid(arr_std,H,W)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "From the calculated mean and sd of arr_std, we see the image has been normalized.  Furthermore from replotting the images we see that there has been no change in their appearence as expected.  Thus the normalization is correctly done.\n\nNow, we find the mean image across all people. \nAs you can see, this image is quite blury around all features since people have variation in eye location etc."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "mean_image=arr_std.mean(0)\nplt.imshow(np.reshape(mean_image,[H,W]), cmap = cm.Greys_r)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Now, we remove this mean image from all faces.  This causes all the people have a strange medium grey face which only highlights their variation vs other people."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "arr_std_nomean = arr_std - np.repeat(mean_image,arr.shape[0],0)\n\nimage_grid(arr_std_nomean,H,W)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Now we perform the iterative PCA on these standardized no mean images.  To demonstrate that the reconstruction works we reconstruct a signle person and see good performance."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from numpy.linalg import norm\n\nk=50; L=10\n\nR=copy(arr_std_nomean)   #R is a matrix in which each row is the residual vector after the current eigenvectors have been projected out.\neigvecs=np.zeros([k,H*W])\nCoeffs=np.zeros([im_number,k])  # Coeffs holds the coefficients of the eigenvectors that approximate each image\nvar_remaining=np.zeros(k)\n\nfactor=im_number*H*W\n\nfor e in range(k):\n    print 'starting on eigenvec',e\n    V=np.random.normal(size=H*W)  # V is the \"current vector\" in the eigenvector finding algorithm.\n    V=V/norm(V)\n\n    # Iterate L times through the data to find the next eigenvector.\n    for j in range(L):\n        acc_length=0; acc_explained=0\n        Vprev=V/norm(V)\n        for i in range(im_number):\n            X=R[i,:]\n            d=np.dot(V,X)/norm(V)\n            V=V+d*X\n            #print acc_length,acc_explained\n            acc_length += np.dot(X,X)\n            acc_explained += d*d\n        NV=V/norm(V) # normalized version of updated vector\n        print '%4d: change=%5.4f, total variance=%5.4f, captured variance=%5.4f' % (j,norm(NV-Vprev),acc_length/factor,acc_explained/factor)\n    var_remaining[e]=acc_length/factor\n    eigvecs[e,:]=NV\n    # subtract projection on V from each data vector\n    for i in range(im_number):\n        X=R[i,:]\n        d=np.dot(X,NV)\n        Coeffs[i,e]=d\n        X=X-NV*d\n        R[i,:]=X",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "im=31\nApprox=np.zeros([k+2,H*W])\nApprox[0,:]=mean_image\nerror = [0]*(k+2)\nfor i in range(1,k+1):\n    Approx[i,:]=Approx[i-1,:]+Coeffs[im,i-1]*eigvecs[i-1,:]\nfor i in range(0,k+1):\n    error[i] = np.square(Approx[i,:] - arr_std[im,:]).sum()/(H*W)\nlabels = [\"MSE = %0.2f RMSE = %0.2f\" % (x,np.sqrt(x)) for x in error]\nApprox[k+1,:]=arr_std[im,:]\nimage_grid_2(Approx,H,W,cols=5, labels=labels)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "This method seems to work pretty well with discriminating between people.  A relatively small number of eigen vectors results in 0 error."
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**Mofei** How many eigenvectors do you want to use? Is it necessary to have the error = 0 to discriminating between people?"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}